{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAhmadS/NLP_HW2/blob/main/NLP_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKugniAeQcGt",
        "outputId": "ad2d6ac7-ddca-4c0d-df5a-0ac0bbd53c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRCx-_IwWvxT",
        "outputId": "f5538384-9d9d-4055-e212-432089e89eb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting essential data\n",
        "\n"
      ],
      "metadata": {
        "id": "LYf9wqwEYwO4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSfhkkxP3gzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q hazm\n",
        "!pip install -q dadmatools"
      ],
      "metadata": {
        "id": "znLvol8uYzV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3057712e-68fc-49ce-e21b-02c634df9a21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 KB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "n2iCwQ7T3uBu"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "import hazm\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import itertools\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "vJ1FDzA_Y5VW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Nlp HW2/extracted-phrases.json','r',encoding='utf-8') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "b6WyrXTxmsGr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "phonics_list = []\n",
        "dict_file = open('cmudict.dict', 'r')\n",
        "with dict_file as f:\n",
        "    phonics = [line.rstrip('\\n') for line in f]\n",
        "    for p in phonics:\n",
        "        x = p.split(' ')\n",
        "        words.append(x[0])\n",
        "        phonics_list.append(' '.join(x[1:]))"
      ],
      "metadata": {
        "id": "_kzbejEP6GP7"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phons_uniqe = list(set(itertools.chain(*[ph.split(\" \") for ph in phonics_list])))\n",
        "phons_as_list = [ph.split(\" \") for ph in phonics_list]"
      ],
      "metadata": {
        "id": "zulC4Adu6upO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  x = input()\n",
        "  for ph in phonics:\n",
        "    if x in ph:\n",
        "      print(ph)\n",
        "      break\n"
      ],
      "metadata": {
        "id": "nRDfs3X7_vpT",
        "outputId": "d1b61384-5c9b-44a4-8da9-a5affd6bee33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JH\n",
            "abidjan AE0 B IH0 JH AA1 N\n",
            "AY0\n",
            "adelstein AE1 D AH0 L S T AY0 N\n",
            "AY1\n",
            "abide AH0 B AY1 D\n",
            "UH2\n",
            "abzug(2) AE1 B Z UH2 G\n",
            "ZH\n",
            "abasia AH0 B EY1 ZH Y AH0\n",
            "OW2\n",
            "abaco AE1 B AH0 K OW2\n",
            "ER0\n",
            "aaberg AA1 B ER0 G\n",
            "UW2\n",
            "abdulaziz AE0 B D UW2 L AH0 Z IY1 Z\n",
            "TH\n",
            "aalseth AA1 L S EH0 TH\n",
            "#\n",
            "d'artagnan D AH0 R T AE1 NG Y AH0 N # foreign french\n",
            "UH1\n",
            "aburto AH0 B UH1 R T OW2\n",
            "AA2\n",
            "aaliyah AA2 L IY1 AA2\n",
            "W\n",
            "'bout B AW1 T\n",
            "AO2\n",
            "aancor AA1 N K AO2 R\n",
            "NG\n",
            "abandoning AH0 B AE1 N D AH0 N IH0 NG\n",
            "HH\n",
            "aarhus AA2 HH UW1 S\n",
            "EY0\n",
            "abbate AA1 B EY0 T\n",
            "DH\n",
            "acantha AA0 K AA1 N DH AH0\n",
            "OY1\n",
            "adjoin AH0 JH OY1 N\n",
            "AW2\n",
            "abbenhaus AE1 B AH0 N HH AW2 S\n",
            "CH\n",
            "abramczyk AA1 B R AH0 M CH IH0 K\n",
            "G\n",
            "'gain G EH1 N\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-b7d8d2ccb615>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphonics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(phons_uniqe)"
      ],
      "metadata": {
        "id": "Elz2WriM-1P0",
        "outputId": "39c2dd9f-7148-4801-8ced-04c4c2a78e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['foreign', 'AE2', 'F', 'EH2', 'IY2', 'AY2', 'UW0', 'UW1', 'AH1', 'IY1', 'AH2', 'ER1', 'IH1', 'AA1', 'D', 'AE0', 'AO0', 'EH0', 'AW1', 'JH', 'AY0', 'AY1', 'UH2', 'old', 'M', 'R', 'ZH', 'AE1', 'OW2', 'IY0', 'ER0', 'UW2', 'TH', 'IH0', 'OW1', 'ER2', '#', 'UH1', 'OW0', 'IH2', 'AA2', 'V', 'W', 'UH0', 'N', 'AO2', 'NG', 'AH0', 'K', 'AA0', 'HH', 'EY0', 'DH', 'OY1', 'AO1', 'B', 'AW2', 'EH1', 'T', 'french', 'name', 'Y', 'CH', 'P', 'OY0', 'Z', 'EY2', 'OY2', 'S', 'L', 'SH', 'abbrev', 'G', 'AW0', 'EY1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phons_farsi=[\"\",\"\",\"ف\",\"\",\"ی\",\"ای\",\"یو\",\"یو\",\"ا\",\"ی\",\"ا\",\"ر\",\"ی\",\"ا\",\"د\",\"\",\"و\",\"\",\"و\",\"ج\",\"ای\",\"ای\",\"و\",\"\",\"م\",\"ر\",\"ز\",\"\",\"و\",\"ی\",\"ر\",\"و\",\"ث\",\"ی\",\"و\",\"ر\",\"\",\"و\",\"و\",\"ی\",\"آ\",\"و\",\"و\",\"و\",\"ن\",\"\",\"نگ\",\"ا\",\"ک\",\"آ\",\"ه\",\"ی\",\"ذ\",\"وی\",\"ب\",\"او\",\"\",\"ت\",\"\",\"\",\"ی\",\"چ\",\"پ\",\"وی\",\"ز\",\"ی\",\"وی\",\"س\",\"ل\",\"ش\",\"\",\"گ\",\"\",\"ی\"]"
      ],
      "metadata": {
        "id": "c9-uBAuT8A_e"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(phons_farsi)"
      ],
      "metadata": {
        "id": "dYQDlsI2GXcm",
        "outputId": "cbe2e0db-9ec8-4075-ef24-a4ca8111a979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(phons_uniqe)"
      ],
      "metadata": {
        "id": "kzv2wdGiGbxX",
        "outputId": "6744560d-e037-4965-ef58-bd010e0c8662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('%-16s' % 'eng', '%-16s' % 'farsi')\n",
        "for i in range(74):\n",
        "    print ('%-16s' % phons_farsi[i], '%-16s' % phons_uniqe[i])"
      ],
      "metadata": {
        "id": "KRVgIRBiGpaT",
        "outputId": "ac898942-92ed-4641-f286-9611c18c7d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng              farsi           \n",
            "                 foreign         \n",
            "                 AE2             \n",
            "ف                F               \n",
            "                 EH2             \n",
            "ی                IY2             \n",
            "ای               AY2             \n",
            "یو               UW0             \n",
            "یو               UW1             \n",
            "ا                AH1             \n",
            "ی                IY1             \n",
            "ا                AH2             \n",
            "ر                ER1             \n",
            "ی                IH1             \n",
            "ا                AA1             \n",
            "د                D               \n",
            "                 AE0             \n",
            "و                AO0             \n",
            "                 EH0             \n",
            "و                AW1             \n",
            "ج                JH              \n",
            "ای               AY0             \n",
            "ای               AY1             \n",
            "و                UH2             \n",
            "                 old             \n",
            "م                M               \n",
            "ر                R               \n",
            "ز                ZH              \n",
            "                 AE1             \n",
            "و                OW2             \n",
            "ی                IY0             \n",
            "ر                ER0             \n",
            "و                UW2             \n",
            "ث                TH              \n",
            "ی                IH0             \n",
            "و                OW1             \n",
            "ر                ER2             \n",
            "                 #               \n",
            "و                UH1             \n",
            "و                OW0             \n",
            "ی                IH2             \n",
            "آ                AA2             \n",
            "و                V               \n",
            "و                W               \n",
            "و                UH0             \n",
            "ن                N               \n",
            "                 AO2             \n",
            "نگ               NG              \n",
            "ا                AH0             \n",
            "ک                K               \n",
            "آ                AA0             \n",
            "ه                HH              \n",
            "ی                EY0             \n",
            "ذ                DH              \n",
            "وی               OY1             \n",
            "ب                AO1             \n",
            "او               B               \n",
            "                 AW2             \n",
            "ت                EH1             \n",
            "                 T               \n",
            "                 french          \n",
            "ی                name            \n",
            "چ                Y               \n",
            "پ                CH              \n",
            "وی               P               \n",
            "ز                OY0             \n",
            "ی                Z               \n",
            "وی               EY2             \n",
            "س                OY2             \n",
            "ل                S               \n",
            "ش                L               \n",
            "                 SH              \n",
            "گ                abbrev          \n",
            "                 G               \n",
            "ی                AW0             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main code"
      ],
      "metadata": {
        "id": "ezt1J32nymfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Config"
      ],
      "metadata": {
        "id": "uoztZzu6NAYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dadmatools.models.normalizer import Normalizer\n",
        "\n",
        "dadma_normalizer = Normalizer(\n",
        "    full_cleaning=True,\n",
        "    unify_chars=True,\n",
        "    refine_punc_spacing=True,\n",
        "    remove_extra_space=True,\n",
        "    remove_puncs=True,\n",
        "    remove_html=True,\n",
        "    remove_stop_word=True,\n",
        "    replace_email_with=\"\",\n",
        "    replace_number_with=\"\",\n",
        "    replace_url_with=\"\",\n",
        "    replace_mobile_number_with=None,\n",
        "    replace_emoji_with=None,\n",
        "    replace_home_number_with=None,\n",
        ")\n",
        "\n",
        "dadma_normalizer.normalize(\"بیا ای عقل کل با من که بردابرد او بینی\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gRWJMy0nrWju",
        "outputId": "0d576fb4-6d72-46ae-8863-ebf42f5f839f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'عقل بردابرد بینی'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = hazm.Lemmatizer()\n",
        "stemmer = hazm.Stemmer()"
      ],
      "metadata": {
        "id": "LZ0cqll7Zwdu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp = list(set([x['word'] for x in data]))\n",
        "\n",
        "dual_corp = [phrase for phrase in corp if \" \" in phrase]\n",
        "\n",
        "#to change\n",
        "\n",
        "main_corp = [lemmatizer.lemmatize(word) for word in corp if \" \" not in word]\n",
        "\n",
        "print(f\"number of single words within data is about : {len(main_corp)} and multiple part words count as {len(dual_corp)}\")\n",
        "print(\"----------------------\\n\")\n",
        "print ('%-45s' % 'word', '%-16s' % 'compound')\n",
        "for i in range(15):\n",
        "    print ('%-50s' % dual_corp[i], '%-16s' % main_corp[i])"
      ],
      "metadata": {
        "id": "_9XeR8XowdUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ced6617-c344-4bf3-9682-092522fbe3c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of single words within data is about : 245048 and multiple part words count as 610169\n",
            "----------------------\n",
            "\n",
            "word                                          compound        \n",
            "سرگول نمک                                          استمناء         \n",
            "حمله مغول به ژاپن                                  قرقسا           \n",
            "نه رنگ فیلم                                        رحیم‌خان        \n",
            "آتیلا فیلم 1954                                    گوزبورن         \n",
            "احمد متوسلیان                                      اشکیک           \n",
            "ربیعهبن ملاعب الاسنه                               پلاسیدنی        \n",
            "منصور السالم                                       ساعده           \n",
            "آلفرد کلاینر                                       مخثم            \n",
            "جوشکاری با تشعشعات الکترونی                        چغزیدن          \n",
            "فدریکو باروچی                                      پالئوگرافی      \n",
            "اتحادیه فوتبال فنلاند                              جابق            \n",
            "فرودگاه شهرستان هیوستن مینه‌سوتا                   هبج             \n",
            "حصن لبراله                                         بدورث           \n",
            "غلامرضا اشرافی                                     سعدل            \n",
            "دانشکده کشاورزی دانشگاه تبریز                      غانژ            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dadmatools.pipeline.language as language\n",
        "\n",
        "pips = 'lem' \n",
        "nlp = language.Pipeline(pips)\n",
        "\n",
        "print(nlp.analyze_pipes(pretty=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ShvxXYdXJ0Y",
        "outputId": "e2f96dd8-86cd-4e64-ec50-b6bb25c692c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file /root/.pernlp/fa_tokenizer.pt: : 639kB [00:01, 409kB/s]                           \n",
            "Downloading file /root/.pernlp/fa_mwt.pt: : 721kB [00:01, 464kB/s]                         \n",
            "Downloading file /root/.pernlp/fa_lemmatizer.pt: : 4.69MB [00:01, 2.77MB/s]                          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================= Pipeline Overview =============================\u001b[0m\n",
            "\n",
            "#   Component   Assigns       Requires   Scores   Retokenizes\n",
            "-   ---------   -----------   --------   ------   -----------\n",
            "0   tokenizer                                     True       \n",
            "                                                             \n",
            "1   lemmatize   token.lemma                       False      \n",
            "\n",
            "\u001b[38;5;2m✔ No problems found.\u001b[0m\n",
            "{'summary': {'tokenizer': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': True}, 'lemmatize': {'assigns': ['token.lemma'], 'requires': [], 'scores': [], 'retokenizes': False}}, 'problems': {'tokenizer': [], 'lemmatize': []}, 'attrs': {'token.lemma': {'assigns': ['lemmatize'], 'requires': []}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"corpus.txt\",\"rb\") as f:\n",
        "  corpo = pickle.load(f)\n",
        "\n",
        "corpo"
      ],
      "metadata": {
        "id": "wtvAazXLhkjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = main_corp.copy()\n",
        "corpus.extend(corpo)\n",
        "corpus = list(set(corpus))\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dAN6kCzie1v",
        "outputId": "3d8da5a4-0957-491e-cdf4-9fc1b83de970"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250004"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = list(set(corpo))\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLtriJNNo35v",
        "outputId": "aeaf3457-794a-4f4b-ccee-339ddc521a91"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35316"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in corpu:\n",
        "  if \"پخت#پز\" == x:\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "8rwinN6ri-zw",
        "outputId": "ae9aebb1-26cf-4265-aeac-b8f19369349d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "پخت#پز\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roles = [x[2] for x in hazm.words_list()]\n",
        "roles = list(set(itertools.chain(*roles)))\n",
        "roles"
      ],
      "metadata": {
        "id": "febyfjwQr0hc",
        "outputId": "a30f646b-6d64-4407-bd05-3c268a68676b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CONJ',\n",
              " 'ZVR',\n",
              " 'CL',\n",
              " 'RES',\n",
              " 'NIN',\n",
              " 'PS',\n",
              " 'COMP',\n",
              " 'AJC',\n",
              " 'PR',\n",
              " 'V',\n",
              " 'AJ',\n",
              " 'INT',\n",
              " 'N',\n",
              " 'PL',\n",
              " 'NUM',\n",
              " 'P',\n",
              " 'PRO',\n",
              " 'ADV',\n",
              " 'POSTP',\n",
              " 'DET']"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_list = [\"ند\",\"یم\",\"ید\",\"ی\",\"تان\",\"ش\",\"ت\",\"شان\",\"مان\",\"م\",\"‍ها\",\"ات\",\"ان\",\"ین\",\"ون\"]\n",
        "corpu = []\n",
        "for word in corpus:\n",
        "  corpu.append(word)\n",
        "  corpu.append(lemmatizer.lemmatize(word))\n",
        "  for ele in add_list:\n",
        "    corpu.append(word+ele)\n",
        "\n",
        "len(corpu)"
      ],
      "metadata": {
        "id": "SlN7tsHwpAyJ",
        "outputId": "78ef41ae-21b0-4bba-85cf-861d1af2aa8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600372"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"کلاهم را گم کردم.\")"
      ],
      "metadata": {
        "id": "BT3X8rfIjmY-",
        "outputId": "ae6aabaf-47df-49bf-b6be-a7cdf1786ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'کلاهم را گم کردم.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'corpus':corpu,\n",
        "    'pipe':nlp,\n",
        "    'normalizer':dadma_normalizer,\n",
        "    'lemmatizer':hazm.Lemmatizer(),\n",
        "    'translator':None,\n",
        "    'word_tokenizer':hazm.WordTokenizer(),\n",
        "    'sent_tokenizer':hazm.SentenceTokenizer()\n",
        "}"
      ],
      "metadata": {
        "id": "qP0mg4wDOMIm"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class foreign_word_detector():\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      args\n",
        "      ):\n",
        "    self.corpus = args['corpus']\n",
        "    self.lang_pipe = args['pipe']\n",
        "    self.normalizer = args['normalizer']\n",
        "    self.lemmatizer = args['lemmatizer']\n",
        "    self.translator = args['translator']\n",
        "    self.word_tokenizer = args['word_tokenizer']\n",
        "    self.sent_tokenizer = args['sent_tokenizer']\n",
        "\n",
        "  def detect(self, text):\n",
        "    sentenced = self.sent_tokenizer.tokenize(text)\n",
        "    sentenced = [sent.replace(\"\\u200c\",\" \") for sent in sentenced]\n",
        "    normalized = [self.normalizer.normalize(sent) for sent in sentenced]\n",
        "    lemmed = [str(self.lang_pipe(sent)) for sent in normalized]\n",
        "\n",
        "    words_list = [self.word_tokenizer.tokenize(sent) for sent in lemmed]\n",
        "    words_list = list(itertools.chain(*words_list))\n",
        "\n",
        "    lemmed_words_list = [lemmatizer.lemmatize(word) for word in words_list]\n",
        "\n",
        "    output = dict()\n",
        "    out = []\n",
        "\n",
        "    for word in words_list:\n",
        "      if word not in self.corpus:\n",
        "        out.append(word)\n",
        "        begin = text.find(word)\n",
        "        output[word] = [begin,begin+len(word)]\n",
        "    \n",
        "    return out, output\n",
        "          "
      ],
      "metadata": {
        "id": "abisr-pQyq1p"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  detector = foreign_word_detector(args)\n",
        "\n",
        "  text = \"\"\n",
        "  print(\"enter your sample text.\\nenter an empty string if you want to end the process\")\n",
        "  while True : \n",
        "    text = input()\n",
        "    if text == \"\": \n",
        "      break\n",
        "    \n",
        "    out, output = detector.detect(text)\n",
        "    print(out)\n",
        "    print(output)\n"
      ],
      "metadata": {
        "id": "gFnE-4jRs3Hp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvJUGGdQw1mH",
        "outputId": "4230155e-984b-4f0b-b84e-f8d9f838cdaf"
      },
      "execution_count": 81,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter your sample text.\n",
            "enter an empty string if you want to end the process\n",
            "پدرت؟ کدام پدرت؟\n",
            "[]\n",
            "{}\n",
            "ببین. تایم ندارم.\n",
            "['ببین', 'یم']\n",
            "{'ببین': [0, 4], 'یم': [8, 10]}\n",
            "امروز تایم ندارم.\n",
            "['یم']\n",
            "{'یم': [8, 10]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"خوبند\")"
      ],
      "metadata": {
        "id": "vbPBjZ8DjSfT",
        "outputId": "c3ec75a8-624e-4350-e005-34d6ca083bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'خوبند'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem is: using stemmer, we get lots of errors; while using lemmatizer, pronouns are not ommited from the word.\n",
        "\n",
        "\n",
        "one way to deal with it would be to apply stemming right after dealing with the word origin.\n",
        "\n",
        "another way would be to find a way to work with the tokenizer introduced in the next cell, since it gives us specific features."
      ],
      "metadata": {
        "id": "4ftp21Xf7JL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(\"من خوبم.آنا خوبه ؟\")"
      ],
      "metadata": {
        "id": "_WSN_wuYmRMT",
        "outputId": "9d49db29-3955-4fb8-e1e2-2c3bb1877c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "من خوبم.آنا خوبه ؟ "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZeTOSNhui0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}